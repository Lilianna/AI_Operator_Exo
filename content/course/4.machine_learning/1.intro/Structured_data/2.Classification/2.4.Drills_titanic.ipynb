{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Let's dive into the serious business now!\n",
    "\n",
    "### Description\n",
    "[Kaggle](http://www.kagle.com/) is a great platform to learn machine learning. They offer free datasets and organize competitions around them. You can even be paid if you win one of them!\n",
    "\n",
    "Now that you know how to build a classifier, try with [the titanic dataset!](https://www.kaggle.com/c/titanic).\n",
    "\n",
    "### Steps\n",
    "1. Download the dataset.\n",
    "2. Import it in a jupyter notebook.\n",
    "3. Analyse the data.\n",
    "4. Divide the dataset. (train data and test data)\n",
    "5. Build a classifier using the algorithm of you choice and fit it with your train data.\n",
    "6. Evaluate the model with your test data.\n",
    "7. When you're satisfied with the result, fit your model with the complete dataset.\n",
    "8. Predict the Kaggle's test set and [submit your prediciton](https://www.kaggle.com/c/titanic/overview).\n",
    "9. Which score did you get?\n",
    "\n",
    "**DISCLAIMER:** If you look at Kaggle's leaderboard, you will see a lot of people have a score of 100%. They just found the name of people that survived online. Great lesson here, when you are learning something, never compare yourself to others. All that matters is what you've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 4: Titanic Dataset Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.64      0.62        50\n",
      "           1       0.40      0.35      0.38        34\n",
      "\n",
      "    accuracy                           0.52        84\n",
      "   macro avg       0.50      0.50      0.50        84\n",
      "weighted avg       0.51      0.52      0.52        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add you code here...\n",
    "\n",
    "# Exercise 4: Titanic Dataset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the Titanic dataset (Downloaded from Kaggle)\n",
    "titanic_data = pd.read_csv('assets/titanic.csv')\n",
    "\n",
    "# Analyze the data and perform any necessary preprocessing\n",
    "# (Data cleaning, handling missing values, feature engineering, etc.)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = titanic_data.drop('Survived', axis=1)\n",
    "y = titanic_data['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a classifier (e.g., Random Forest) and fit it with the train data\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model with the test data\n",
    "y_pred = random_forest.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Exercise 4: Titanic Dataset Classification Report\\n\")\n",
    "print(report)\n",
    "\n",
    "# Once satisfied with the result, fit the model with the complete dataset and predict Kaggle's\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
